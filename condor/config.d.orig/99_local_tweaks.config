############################################
#
# 99_local_tweaks.config
# 
# This config file should be used for all manual changes
# on this machine. The other config files should not
# be modified, as they will be overwritten by puppet. 
# Include permanent changes in puppet, and temporary 
# changes or machine-specific changes here.
#
############################################

# To avoid spamming others while debugging issues
# CONDOR_ADMIN = farrukh.aftab.khan@gmail.com

# To enable debug level
# NEGOTIATOR_DEBUG = D_FULLDEBUG,D_MATCH
# COLLECTOR_DEBUG = D_FULLDEBUG,D_SECURITY
# SCHEDD_DEBUG = D_FULLDEBUG


NEGOTIATOR_DEBUG = D_FULLDEBUG

############################################
# DODAS mapping
############################################
COLLECTOR_CLASSAD_USER_MAP_NAMES = siteusers
CLASSAD_USER_MAPFILE_siteusers = /etc/condor/siteusers_global.map

#ddavila 2018-05-03:
##A slightly different requirements are needed for the Main Collector, in case the startd tries to bypass the secondaries.
##Do not let any startd to connect directly to the main collector
COLLECTOR_REQUIREMENTS = MyType=!="Machine" || !regexp("^siteuser_", AuthenticatedIdentity)



# ddavila 2018-06-18
# Icreasing the log size to reach 24 hrs.
MAX_COLLECTOR_LOG = 16000000


COLLECTOR_FORWARD_WATCH_LIST=State,Cpus,Memory,IdleJobs,Activity


# Added by Brian Bockelman on 13 March.
# Disabling rewriting doubles the query speed.
ENABLE_ADDRESS_REWRITING = false



# ddavila: NEW KNOBS FOR VERSION 8.7.1 (Suggested by Tod)
# Maximum number of forked query processes to 4
# ddavila 2017-10-03 changed from 4 to 6
# https://cms-logbook.cern.ch/elog/GlideInWMS/5636?mail0=36%20recipients
# Reducing back to 4 due to issues with memory (Farrukh 2017-10-31)
# Further Reducing to 3 due to issues with memory (Diego 2017-11-01)
COLLECTOR_QUERY_WORKERS = 8


# Number of forked query processes reserved for # the negotiator to 2
# ddavila 2017-10-03 changed from 2 to 3 
# https://cms-logbook.cern.ch/elog/GlideInWMS/5636?mail0=36%20recipients
# ddavila 2017-11-01: reducing from 3 to 2 due to memory issues 
# Further Reducing to 1 due to issues with memory (Diego 2017-11-01)
COLLECTOR_QUERY_WORKERS_RESERVE_FOR_HIGH_PRIO = 3
# Amount of time in seconds that clients of the collector are willing to wait
# for a response.
QUERY_TIMEOUT = 120

#CONDOR_HOST1=cmssrv221.fnal.gov
#CONDOR_HOST2=vocms0815.cern.ch


###############################################################################
# ddavila 2017-11-09: Forcing the negotiators to stay down, until FNAL's CM
# whitelists the new CERN's CM

#DAEMON_LIST=MASTER,  COLLECTOR, REPLICATION, COLLECTOR9620, COLLECTOR9621, COLLECTOR9622, COLLECTOR9623, COLLECTOR9624, COLLECTOR9625, COLLECTOR9626, COLLECTOR9627, COLLECTOR9628, COLLECTOR9629, COLLECTOR9630, COLLECTOR9631, COLLECTOR9632, COLLECTOR9633, COLLECTOR9634, COLLECTOR9635, COLLECTOR9636, COLLECTOR9637, COLLECTOR9638, COLLECTOR9639, COLLECTOR9640, COLLECTOR9641, COLLECTOR9642, COLLECTOR9643, COLLECTOR9644, COLLECTOR9645, COLLECTOR9646, COLLECTOR9647, COLLECTOR9648, COLLECTOR9649, COLLECTOR9650, COLLECTOR9651, COLLECTOR9652, COLLECTOR9653, COLLECTOR9654, COLLECTOR9655, COLLECTOR9656, COLLECTOR9657, COLLECTOR9658, COLLECTOR9659, COLLECTOR9660, COLLECTOR9661, COLLECTOR9662, COLLECTOR9663, COLLECTOR9664, COLLECTOR9665, COLLECTOR9666, COLLECTOR9667, COLLECTOR9668, COLLECTOR9669, COLLECTOR9670, COLLECTOR9671, COLLECTOR9672, COLLECTOR9673, COLLECTOR9674, COLLECTOR9675, COLLECTOR9676, COLLECTOR9677, COLLECTOR9678, COLLECTOR9679, COLLECTOR9680, COLLECTOR9681, COLLECTOR9682, COLLECTOR9683, COLLECTOR9684, COLLECTOR9685, COLLECTOR9686, COLLECTOR9687, COLLECTOR9688, COLLECTOR9689, COLLECTOR9690, COLLECTOR9691, COLLECTOR9692, COLLECTOR9693, COLLECTOR9694, COLLECTOR9695, COLLECTOR9696, COLLECTOR9697, COLLECTOR9698, COLLECTOR9699, COLLECTOR9700, COLLECTOR9701, COLLECTOR9702, COLLECTOR9703, COLLECTOR9704, COLLECTOR9705, COLLECTOR9706, COLLECTOR9707, COLLECTOR9708, COLLECTOR9709, COLLECTOR9710, COLLECTOR9711, COLLECTOR9712, COLLECTOR9713, COLLECTOR9714, COLLECTOR9715, COLLECTOR9716, COLLECTOR9717, COLLECTOR9718, COLLECTOR9719, COLLECTOR9720, COLLECTOR9721, COLLECTOR9722, COLLECTOR9723, COLLECTOR9724, COLLECTOR9725, COLLECTOR9726, COLLECTOR9727, COLLECTOR9728, COLLECTOR9729, COLLECTOR9730, REPLICATIONT1, REPLICATIONUS
#
#DC_DAEMON_LIST =+ REPLICATION
#DC_DAEMON_LIST =+ REPLICATIONT1, REPLICATIONUS

###############################################################################



#MAX_COLLECTOR_LOG = 2000000

# Temporarily adjusting fair share across T2s
# as requested per: https://cms-logbook.cern.ch/elog/GlideInWMS/5846
# (Farrukh 2017-12-1)
GROUP_QUOTA_DYNAMIC_production = 0.75
GROUP_QUOTA_DYNAMIC_analysis = 0.25

###############################################################################
# ddavila 2018-02-05: Testing New Quotas
# https://cms-logbook.cern.ch/elog/GlideInWMS/5930
################################################################################
GROUP_ACCEPT_SURPLUS = True
GROUP_NAMES = production, analysis, highprio, tier0

#I think the next two lines are not necessaries
GROUP_QUOTA_DYNAMIC=0.0
GROUP_QUOTA=0

GROUP_QUOTA_DYNAMIC_highprio = 0.99
GROUP_QUOTA_DYNAMIC_production=0.0060
GROUP_QUOTA_DYNAMIC_analysis=0.0040
GROUP_QUOTA_DYNAMIC_tier0=0.0

NEGOTIATORUS.GROUP_QUOTA_DYNAMIC_highprio = 0.99
NEGOTIATORUS.GROUP_QUOTA_DYNAMIC_production = 0.0075
NEGOTIATORUS.GROUP_QUOTA_DYNAMIC_analysis = 0.0025
NEGOTIATORUS.GROUP_QUOTA_DYNAMIC_tier0 = 0.0

NEGOTIATORT1.GROUP_QUOTA_DYNAMIC_highprio = 0.99
NEGOTIATORT1.GROUP_QUOTA_DYNAMIC_production = 0.0085
NEGOTIATORT1.GROUP_QUOTA_DYNAMIC_analysis = 0.0005
NEGOTIATORT1.GROUP_QUOTA_DYNAMIC_tier0 = 0.0010

NEGOTIATOR_ALLOW_QUOTA_OVERSUBSCRIPTION = false
GROUP_QUOTA_highprio=

NEGOTIATORT1.GROUP_SORT_EXPR = ifThenElse(AccountingGroup is null, 0.0, ifThenElse(regexp("^tier0", AccountingGroup), -4.0, ifThenElse(regexp("^production", AccountingGroup), -3.0, ifThenElse(regexp("^analysis", AccountingGroup), -2.0, -1.0))))

###############################################################################
# ddavila 2018-02-12: Don't take into consideration the GLIDIEN_ToDie while counting available resources
# https://cms-logbook.cern.ch/elog/GlideInWMS/5973
################################################################################
#NEGOTIATOR_SLOT_POOLSIZE_CONSTRAINT = (State=!="Unclaimed" || isUndefined(GLIDEIN_ToRetire) || isUndefined(GLIDEIN_ToDie) || ((time() < GLIDEIN_ToRetire) && (time()+6*60*60 < GLIDEIN_ToDie)))
NEGOTIATOR_SLOT_POOLSIZE_CONSTRAINT = (State=!="Unclaimed" || isUndefined(GLIDEIN_ToRetire) || isUndefined(GLIDEIN_ToDie) || (time() < GLIDEIN_ToRetire))

COLLECTOR9663.DEBUG=D_FULLDEBUG
